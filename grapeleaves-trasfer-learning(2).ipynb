{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, GlobalAveragePooling2D, UpSampling2D, Input, LeakyReLU\nfrom keras.layers import Conv2DTranspose\nfrom tensorflow.keras.layers import MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom sklearn.neural_network import MLPClassifier\nfrom keras.utils.vis_utils import plot_model\nfrom keras.layers.core import Dense, Activation, Dropout\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import confusion_matrix\nimport keras\nfrom keras import layers\nimport random as rnd\nimport cv2\nimport matplotlib.image as mpimg\nfrom PIL import Image\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-05T13:26:34.124581Z","iopub.execute_input":"2022-08-05T13:26:34.125054Z","iopub.status.idle":"2022-08-05T13:26:40.458729Z","shell.execute_reply.started":"2022-08-05T13:26:34.124923Z","shell.execute_reply":"2022-08-05T13:26:40.457589Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Creating DataFrame","metadata":{}},{"cell_type":"code","source":"main_df = pd.DataFrame()\nmain_path = '../input/grapevine-leaves-image-dataset/Grapevine_Leaves_Image_Dataset/'\npath_Ak = main_path + 'Ak'\npath_Ala_Idris = main_path + 'Ala_Idris'\npath_Buzgulu = main_path + 'Buzgulu'\npath_Dimnit = main_path + 'Dimnit'\npath_Nazli = main_path + 'Nazli'\n\nmain_df['images'] = os.listdir(path_Ak) + os.listdir(path_Ala_Idris) + os.listdir(path_Buzgulu) + os.listdir(path_Dimnit) + os.listdir(path_Nazli)\n\nclasses = []\npaths = []\nfor image in main_df['images']:\n    class_ = image.split(' (')[0]\n    classes.append(class_)\n    paths.append(main_path+class_+'/'+image)\n\nmain_df['classes'] = classes\nmain_df['path'] = paths\nprint(len(main_df))\nmain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-05T13:26:40.460887Z","iopub.execute_input":"2022-08-05T13:26:40.461439Z","iopub.status.idle":"2022-08-05T13:26:40.739357Z","shell.execute_reply.started":"2022-08-05T13:26:40.461409Z","shell.execute_reply":"2022-08-05T13:26:40.738454Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"X_train1, X_test, y_train1, y_test = train_test_split(main_df[['path', 'classes']], \n                                                  main_df[['classes']], \n                                                  test_size=0.2, \n                                                  random_state=101)\nX_train, X_val, y_train, y_val = train_test_split(X_train1[['path', 'classes']], \n                                                  X_train1[['classes']], \n                                                  test_size=0.2, \n                                                  random_state=101)\nprint(len(X_train), len(X_val), len(X_test))","metadata":{"execution":{"iopub.status.busy":"2022-08-05T13:26:40.743531Z","iopub.execute_input":"2022-08-05T13:26:40.744140Z","iopub.status.idle":"2022-08-05T13:26:40.765084Z","shell.execute_reply.started":"2022-08-05T13:26:40.744104Z","shell.execute_reply":"2022-08-05T13:26:40.763984Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15,12))\nfor idx,i in enumerate(main_df.classes.unique()):\n    plt.subplot(4,7,idx+1)\n    df = main_df[main_df['classes'] ==i].reset_index(drop = True)\n    image_path = df.loc[rnd.randint(0, len(df))-1,'path']\n    img = Image.open(image_path)\n    print(img.size)\n    img = img.resize((224,224))\n    plt.imshow(img)\n    plt.axis('off')\n    plt.title(i)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-05T07:26:04.547330Z","iopub.execute_input":"2022-08-05T07:26:04.547715Z","iopub.status.idle":"2022-08-05T07:26:05.121033Z","shell.execute_reply.started":"2022-08-05T07:26:04.547682Z","shell.execute_reply":"2022-08-05T07:26:05.120128Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Random Seed","metadata":{}},{"cell_type":"code","source":"main_path = '../input/grapevine-leaves-image-dataset/Grapevine_Leaves_Image_Dataset/'\nlabels = ['Ak', 'Ala_Idris', 'Buzgulu', 'Dimnit', 'Nazli']\nAk_route = main_path + 'Ak'\nAla_Idris_route = main_path + 'Ala_Idris'\nBuzgulu_route = main_path + 'Buzgulu'\nDimnit_route = main_path + 'Dimnit'\nNazli_route = main_path + 'Nazli'\ncount_bar = {}\ncount_bar['labels'] = labels\ncount_bar['count'] = [len(os.listdir(main_path+i)) for i in labels]\ncount_bar_df = pd.DataFrame(count_bar, index=[1,2,3,4,5])\n\nroot_dir = \"./grape_dataset\"\n#import shutil\n#shutil.rmtree('./grape_dataset')\n    \npath = os.path.join(root_dir, \"training\")\nos.makedirs(path)\nfor i in labels:\n    os.makedirs(os.path.join(path,i))\npath = os.path.join(root_dir, \"validating\")\nos.makedirs(path)\nfor i in labels:\n    os.makedirs(os.path.join(path,i))\npath = os.path.join(root_dir, \"testing\")\nos.makedirs(path)\nfor i in labels:\n    os.makedirs(os.path.join(path,i))\ndef train_test_split(SOURCE, TRAINING, TESTING, VALIDATING, SPLIT_SIZE):\n    files = []\n    for filename in os.listdir(SOURCE):\n        file = SOURCE + filename\n        if os.path.getsize(file) > 0:\n            files.append(filename)\n        else:\n            print(filename + ' is zero length, so ignoring.')\n        \n        import random\n        from shutil import copyfile\n\n        training_length = int((len(files) * SPLIT_SIZE)*SPLIT_SIZE)\n        validating_length = int((len(files) * SPLIT_SIZE)) - training_length\n        testing_length = int(len(files) * (1- SPLIT_SIZE))\n        shuffled_set = random.sample(files, len(files))\n        training_set = shuffled_set[0:training_length]\n        validating_set = shuffled_set[training_length+1:-testing_length]\n        testing_set = shuffled_set[-testing_length:]\n    for filename in training_set:\n        src_file = SOURCE + filename\n        dest_file = TRAINING + filename\n        copyfile(src_file, dest_file)\n    \n    for filename in validating_set:\n        src_file = SOURCE + filename\n        dest_file = VALIDATING + filename\n        copyfile(src_file, dest_file)\n        \n    for filename in testing_set:\n        src_file = SOURCE + filename\n        dest_file = TESTING + filename\n        copyfile(src_file, dest_file)\n        \ntraining_dir = \"./grape_dataset/training\"\ntesting_dir = \"./grape_dataset/testing/\"\nvalidating_dir = \"./grape_dataset/validating\"\nsplit_size = 0.8\n\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfor i in range(10):\n    for i in labels:\n        label_source_dir = \"../input/grapevine-leaves-image-dataset/Grapevine_Leaves_Image_Dataset/\" + str(i) + \"/\"\n        training_label_dir = os.path.join(training_dir, (str(i)+\"/\"))\n        validating_label_dir = os.path.join(validating_dir, (str(i)+\"/\"))\n        testing_label_dir = os.path.join(testing_dir, (str(i)+\"/\"))\n        train_test_split(label_source_dir, training_label_dir, testing_label_dir, validating_label_dir, split_size)\n\n    resnet50_datagen = ImageDataGenerator(rotation_range=20,zoom_range=0.10,brightness_range=[0.6,1.4],channel_shift_range=0.7,width_shift_range=0.15,height_shift_range=0.15,shear_range=0.15,horizontal_flip=True,fill_mode='nearest',preprocessing_function=preprocess_input) \n    train_generator_resnet50 = resnet50_datagen.flow_from_directory(training_dir,  target_size=(227, 227),  batch_size=32,class_mode=\"categorical\",shuffle=True,)\n    val_generator_resnet50 = resnet50_datagen.flow_from_directory(validating_dir,  target_size=(227, 227),  batch_size=32,class_mode=\"categorical\",shuffle=True,)\n    resnet50_datagen_test = ImageDataGenerator(preprocessing_function=preprocess_input) \n    test_generator_resnet50 = resnet50_datagen_test.flow_from_directory(testing_dir,  target_size=(227, 227),  batch_size=32,class_mode=\"categorical\",shuffle=True,)\n    resnet = tf.keras.applications.ResNet50(input_shape=(227,227,3), include_top=False, weights='imagenet', classes=5)\n\n    x = GlobalAveragePooling2D()(resnet.output)\n    x = Dense(units=512, activation='relu')(x)\n    x = Dense(units=512, activation='relu')(x)\n    x = Dropout(0.5)(x)\n\n    output = Dense(units=5,activation = 'softmax')(x)\n    model_resnet = Model(resnet.input, output)\n\n\n\n    opt = SGD(lr=0.001)\n    model_resnet.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n    savebest = tf.keras.callbacks.ModelCheckpoint('resnet_beforefinetuning.h5', save_best_only=True);\n    history_resnet = model_resnet.fit(train_generator_resnet50, \n                                      validation_data=val_generator_resnet50, \n                                      epochs=35, \n                                     callbacks=[savebest])\n\n    model_resnet.evaluate(test_generator_resnet50)[1]","metadata":{"execution":{"iopub.status.busy":"2022-08-04T14:55:01.324222Z","iopub.execute_input":"2022-08-04T14:55:01.324596Z","iopub.status.idle":"2022-08-04T16:26:21.181665Z","shell.execute_reply.started":"2022-08-04T14:55:01.324563Z","shell.execute_reply":"2022-08-04T16:26:21.180670Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"main_path = '../input/grapevine-leaves-image-dataset/Grapevine_Leaves_Image_Dataset/'\nlabels = ['Ak', 'Ala_Idris', 'Buzgulu', 'Dimnit', 'Nazli']\nAk_route = main_path + 'Ak'\nAla_Idris_route = main_path + 'Ala_Idris'\nBuzgulu_route = main_path + 'Buzgulu'\nDimnit_route = main_path + 'Dimnit'\nNazli_route = main_path + 'Nazli'\ncount_bar = {}\ncount_bar['labels'] = labels\ncount_bar['count'] = [len(os.listdir(main_path+i)) for i in labels]\nprint(count_bar)\ncount_bar_df = pd.DataFrame(count_bar, index=[1,2,3,4,5])\nax = sns.countplot(x=labels, data=count_bar_df)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T07:26:24.019175Z","iopub.execute_input":"2022-08-05T07:26:24.019540Z","iopub.status.idle":"2022-08-05T07:26:24.206065Z","shell.execute_reply.started":"2022-08-05T07:26:24.019501Z","shell.execute_reply":"2022-08-05T07:26:24.205098Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"root_dir = \"./grape_dataset\"\nimport shutil\nshutil.rmtree('./grape_dataset')\n    \npath = os.path.join(root_dir, \"training\")\nos.makedirs(path)\nfor i in labels:\n    os.makedirs(os.path.join(path,i))\npath = os.path.join(root_dir, \"validating\")\nos.makedirs(path)\nfor i in labels:\n    os.makedirs(os.path.join(path,i))\npath = os.path.join(root_dir, \"testing\")\nos.makedirs(path)\nfor i in labels:\n    os.makedirs(os.path.join(path,i))","metadata":{"execution":{"iopub.status.busy":"2022-08-05T07:26:28.182336Z","iopub.execute_input":"2022-08-05T07:26:28.182883Z","iopub.status.idle":"2022-08-05T07:26:28.193406Z","shell.execute_reply.started":"2022-08-05T07:26:28.182840Z","shell.execute_reply":"2022-08-05T07:26:28.192171Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Train, Validation, Test Split","metadata":{}},{"cell_type":"code","source":"def train_test_split(SOURCE, TRAINING, TESTING, VALIDATING, SPLIT_SIZE):\n    files = []\n    for filename in os.listdir(SOURCE):\n        file = SOURCE + filename\n        if os.path.getsize(file) > 0:\n            files.append(filename)\n        else:\n            print(filename + ' is zero length, so ignoring.')\n        \n        import random\n        from shutil import copyfile\n\n        training_length = int((len(files) * SPLIT_SIZE)*SPLIT_SIZE)\n        validating_length = int((len(files) * SPLIT_SIZE)) - training_length\n        testing_length = int(len(files) * (1- SPLIT_SIZE))\n        shuffled_set = random.sample(files, len(files))\n        training_set = shuffled_set[0:training_length]\n        validating_set = shuffled_set[training_length+1:-testing_length]\n        testing_set = shuffled_set[-testing_length:]\n    for filename in training_set:\n        src_file = SOURCE + filename\n        dest_file = TRAINING + filename\n        copyfile(src_file, dest_file)\n    \n    for filename in validating_set:\n        src_file = SOURCE + filename\n        dest_file = VALIDATING + filename\n        copyfile(src_file, dest_file)\n        \n    for filename in testing_set:\n        src_file = SOURCE + filename\n        dest_file = TESTING + filename\n        copyfile(src_file, dest_file)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T07:26:41.635064Z","iopub.execute_input":"2022-08-05T07:26:41.635432Z","iopub.status.idle":"2022-08-05T07:26:41.645393Z","shell.execute_reply.started":"2022-08-05T07:26:41.635402Z","shell.execute_reply":"2022-08-05T07:26:41.644340Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"training_dir = \"./grape_dataset/training\"\ntesting_dir = \"./grape_dataset/testing/\"\nvalidating_dir = \"./grape_dataset/validating\"\nsplit_size = 0.8\n\nfor i in labels:\n    label_source_dir = \"../input/grapevine-leaves-image-dataset/Grapevine_Leaves_Image_Dataset/\" + str(i) + \"/\"\n    training_label_dir = os.path.join(training_dir, (str(i)+\"/\"))\n    validating_label_dir = os.path.join(validating_dir, (str(i)+\"/\"))\n    testing_label_dir = os.path.join(testing_dir, (str(i)+\"/\"))\n    train_test_split(label_source_dir, training_label_dir, testing_label_dir, validating_label_dir, split_size)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T07:26:43.270987Z","iopub.execute_input":"2022-08-05T07:26:43.271677Z","iopub.status.idle":"2022-08-05T07:26:47.263263Z","shell.execute_reply.started":"2022-08-05T07:26:43.271633Z","shell.execute_reply":"2022-08-05T07:26:47.261822Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"os.listdir('./grape_dataset/validating/Ak')","metadata":{"execution":{"iopub.status.busy":"2022-08-05T07:26:47.265195Z","iopub.execute_input":"2022-08-05T07:26:47.265941Z","iopub.status.idle":"2022-08-05T07:26:47.285331Z","shell.execute_reply.started":"2022-08-05T07:26:47.265894Z","shell.execute_reply":"2022-08-05T07:26:47.284194Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation with keras","metadata":{}},{"cell_type":"code","source":"def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n    train_datagen = ImageDataGenerator(rescale=1.0/255.,\n                                     rotation_range=40,\n                                     width_shift_range=0.2,\n                                     height_shift_range=0.2,\n                                     zoom_range=0.1,\n                                     horizontal_flip=True,\n                                     vertical_flip=True,\n                                     fill_mode='nearest')\n    train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n                                                      batch_size=100,\n                                                      class_mode='categorical',\n                                                      target_size=(300, 300))\n    validation_datagen = ImageDataGenerator(rescale=1.0/255.,\n                                     rotation_range=40,\n                                     width_shift_range=0.2,\n                                     height_shift_range=0.2,\n                                     zoom_range=0.1,\n                                     horizontal_flip=True,\n                                     vertical_flip=True,\n                                     fill_mode='nearest')\n    validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n                                                                batch_size=50,\n                                                                class_mode='categorical',\n                                                                target_size=(300, 300))\n\n    return train_generator, validation_generator","metadata":{"execution":{"iopub.status.busy":"2022-08-05T07:27:05.670263Z","iopub.execute_input":"2022-08-05T07:27:05.670628Z","iopub.status.idle":"2022-08-05T07:27:05.678889Z","shell.execute_reply.started":"2022-08-05T07:27:05.670599Z","shell.execute_reply":"2022-08-05T07:27:05.677819Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_generator, validation_generator = train_val_generators(training_dir, validating_dir)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T07:27:05.860602Z","iopub.execute_input":"2022-08-05T07:27:05.860950Z","iopub.status.idle":"2022-08-05T07:27:06.070383Z","shell.execute_reply.started":"2022-08-05T07:27:05.860920Z","shell.execute_reply":"2022-08-05T07:27:06.069341Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# ResNet50","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.resnet50 import preprocess_input\nresnet50_datagen = ImageDataGenerator(\n    rotation_range=20,\n    zoom_range=0.10,\n    brightness_range=[0.6,1.4],\n    channel_shift_range=0.7,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    preprocessing_function=preprocess_input\n) \ntrain_generator_resnet50 = resnet50_datagen.flow_from_directory(\n        training_dir,  \n        target_size=(227, 227),  \n        batch_size=32,\n        class_mode=\"categorical\",\n        shuffle=True,\n)\nval_generator_resnet50 = resnet50_datagen.flow_from_directory(\n        validating_dir,  \n        target_size=(227, 227),  \n        batch_size=32,\n        class_mode=\"categorical\",\n        shuffle=True,\n)\nresnet50_datagen_test = ImageDataGenerator(\n    preprocessing_function=preprocess_input\n) \ntest_generator_resnet50 = resnet50_datagen_test.flow_from_directory(\n        testing_dir,  \n        target_size=(227, 227),  \n        batch_size=32,\n        class_mode=\"categorical\",\n        shuffle=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-08-04T17:00:46.559552Z","iopub.execute_input":"2022-08-04T17:00:46.559934Z","iopub.status.idle":"2022-08-04T17:00:46.874752Z","shell.execute_reply.started":"2022-08-04T17:00:46.559901Z","shell.execute_reply":"2022-08-04T17:00:46.873402Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"resnet = tf.keras.applications.ResNet50(input_shape=(227,227,3), include_top=False, weights='imagenet', classes=5)\n\nx = GlobalAveragePooling2D()(resnet.output)\nx = Dense(units=512, activation='relu')(x)\nx = Dense(units=512, activation='relu')(x)\nx = Dropout(0.5)(x)\n\noutput = Dense(units=5,activation = 'softmax')(x)\nmodel_resnet = Model(resnet.input, output)\nmodel_resnet.summary()","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-08-04T17:00:47.357985Z","iopub.execute_input":"2022-08-04T17:00:47.360051Z","iopub.status.idle":"2022-08-04T17:00:48.735014Z","shell.execute_reply.started":"2022-08-04T17:00:47.360009Z","shell.execute_reply":"2022-08-04T17:00:48.733980Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#resnet_learning_rate = 0.001\nopt = SGD(lr=0.001)\nmodel_resnet.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\nsavebest = tf.keras.callbacks.ModelCheckpoint('resnet_beforefinetuning.h5', save_best_only=True);\nhistory_resnet = model_resnet.fit(train_generator_resnet50, \n                                  validation_data=val_generator_resnet50, \n                                  epochs=35, \n                                 callbacks=[savebest])","metadata":{"execution":{"iopub.status.busy":"2022-08-04T17:00:48.737094Z","iopub.execute_input":"2022-08-04T17:00:48.737790Z","iopub.status.idle":"2022-08-04T17:05:52.643546Z","shell.execute_reply.started":"2022-08-04T17:00:48.737751Z","shell.execute_reply":"2022-08-04T17:05:52.642384Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model_resnet.evaluate(test_generator_resnet50)[1]","metadata":{"execution":{"iopub.status.busy":"2022-08-04T17:05:52.645796Z","iopub.execute_input":"2022-08-04T17:05:52.646184Z","iopub.status.idle":"2022-08-04T17:05:54.151465Z","shell.execute_reply.started":"2022-08-04T17:05:52.646147Z","shell.execute_reply":"2022-08-04T17:05:54.150300Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"f,ax=plt.subplots(2,1,figsize=(10,10)) \n#Assigning the first subplot to graph training loss and validation loss\nax[0].plot(history_resnet.history['loss'],label='Training Loss')\nax[0].plot(history_resnet.history['val_loss'],label='Validation Loss')\n\n#Plotting the training accuracy and validation accuracy\nax[1].plot(history_resnet.history['accuracy'],label='Training Accuracy')\nax[1].plot(history_resnet.history['val_accuracy'],label='Validation Accuracy')\n\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-08-04T17:05:54.153486Z","iopub.execute_input":"2022-08-04T17:05:54.153911Z","iopub.status.idle":"2022-08-04T17:05:54.600922Z","shell.execute_reply.started":"2022-08-04T17:05:54.153868Z","shell.execute_reply":"2022-08-04T17:05:54.598593Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nnum_of_test_samples = 100\nbatch_size = 32\nY_pred_res = model_resnet.predict_generator(test_generator_resnet50, num_of_test_samples // batch_size+1)\ny_pred_res = np.argmax(Y_pred_res, axis=1)\nprint('Confusion Matrix')\nconf_matrix_res = confusion_matrix(test_generator_resnet50.classes, y_pred_res)\ncm_res = np.array2string(conf_matrix_res)\nprint(conf_matrix_res)","metadata":{"execution":{"iopub.status.busy":"2022-08-04T17:05:54.603618Z","iopub.execute_input":"2022-08-04T17:05:54.604594Z","iopub.status.idle":"2022-08-04T17:05:56.345239Z","shell.execute_reply.started":"2022-08-04T17:05:54.604551Z","shell.execute_reply":"2022-08-04T17:05:56.344192Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"resnet50_datagen = ImageDataGenerator(\n    rotation_range=20,\n    zoom_range=0.10,\n    brightness_range=[0.6,1.4],\n    channel_shift_range=0.7,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    preprocessing_function=preprocess_input\n) \n\n\nkf = KFold(n_splits = 10)\nkfold = StratifiedKFold(n_splits=10,shuffle=True,random_state=42)\nresults = []\n\nY = X_train1[['classes']]\ntrain_x = X_train1.drop(['classes'],axis=1)\n\nfor train_index, val_index in kf.split(np.zeros(400),Y):\n    training_data = X_train1.iloc[train_index]\n    validation_data = X_train1.iloc[val_index]\n    training_set = resnet50_datagen.flow_from_dataframe(dataframe = training_data, \n                                                      x_col=\"path\", \n                                                      y_col=\"classes\",\n                                                      class_mode=\"categorical\",\n                                                      target_size=(227, 227), \n                                                      batch_size=32)\n    validation_set = resnet50_datagen.flow_from_dataframe(dataframe = validation_data, \n                                                        x_col = \"path\", \n                                                        y_col = \"classes\",\n                                                        class_mode = \"categorical\",\n                                                        target_size = (227, 227), \n                                                        batch_size = 32)\n    resnet = tf.keras.applications.ResNet50(input_shape=(227,227,3), include_top=False, weights='imagenet', classes=5)\n    x = GlobalAveragePooling2D()(resnet.output)\n    x = Dense(units=512, activation='relu')(x)\n    x = Dense(units=512, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    output = Dense(units=5,activation = 'softmax')(x)\n    model_resnet = Model(resnet.input, output)\n    \n    opt = SGD(lr=0.001)\n    model_resnet.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n    history_resnet = model_resnet.fit(training_set, validation_data=validation_set, epochs=30)\n\n    resu = model_resnet.evaluate(test_generator_resnet50)\n    results.append(resu)\n    print(resu)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2022-08-04T17:05:56.347072Z","iopub.execute_input":"2022-08-04T17:05:56.347896Z","iopub.status.idle":"2022-08-04T17:48:17.990141Z","shell.execute_reply.started":"2022-08-04T17:05:56.347849Z","shell.execute_reply":"2022-08-04T17:48:17.989160Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Inception_V3","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.inception_v3 import preprocess_input\ninception_v3_datagen = ImageDataGenerator(\n    rotation_range=20,\n    zoom_range=0.10, \n    brightness_range=[0.6,1.4],\n    channel_shift_range=0.7,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    preprocessing_function=preprocess_input\n)\ntrain_generator_inception_v3 = inception_v3_datagen.flow_from_directory(\n        training_dir,  \n        target_size=(300, 300),  \n        batch_size=32,\n        class_mode=\"categorical\",\n        shuffle=True,\n)\nval_generator_inception_v3 = inception_v3_datagen.flow_from_directory(\n        validating_dir,  \n        target_size=(300, 300),  \n        batch_size=32,\n        class_mode=\"categorical\",\n        shuffle=True,\n)\ninception_v3_datagen_test = ImageDataGenerator(\n    preprocessing_function=preprocess_input\n)\ntest_generator_inception_v3 = inception_v3_datagen_test.flow_from_directory(\n        testing_dir,  \n        target_size=(300, 300),  \n        batch_size=32,\n        class_mode=\"categorical\",\n        shuffle=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T07:40:07.750279Z","iopub.execute_input":"2022-08-05T07:40:07.750642Z","iopub.status.idle":"2022-08-05T07:40:08.065023Z","shell.execute_reply.started":"2022-08-05T07:40:07.750613Z","shell.execute_reply":"2022-08-05T07:40:08.064130Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"InceptionV3_model = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n\nfor layer in InceptionV3_model.layers[:-15]:\n    layer.trainable = False\n\nx = InceptionV3_model.output\nx = GlobalAveragePooling2D()(x)\nx = Flatten()(x)\nx = Dense(units=512, activation='relu')(x)\nx = Dropout(0.3)(x)\nx = Dense(units=512, activation='relu')(x)\nx = Dropout(0.3)(x)\noutput  = Dense(units=5, activation='softmax')(x)\nmodel_inception = Model(InceptionV3_model.input, output)\n\nmodel_inception.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-05T07:40:08.386038Z","iopub.execute_input":"2022-08-05T07:40:08.387363Z","iopub.status.idle":"2022-08-05T07:40:14.064304Z","shell.execute_reply.started":"2022-08-05T07:40:08.387323Z","shell.execute_reply":"2022-08-05T07:40:14.063315Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\nmodel_inception.compile(\n        optimizer=optimizer,\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\"])\nhistory_inception = model_inception.fit(train_generator_inception_v3, steps_per_epoch=4, epochs=25, validation_data=val_generator_inception_v3, validation_steps=2)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T07:40:14.066096Z","iopub.execute_input":"2022-08-05T07:40:14.066913Z","iopub.status.idle":"2022-08-05T07:44:09.285159Z","shell.execute_reply.started":"2022-08-05T07:40:14.066876Z","shell.execute_reply":"2022-08-05T07:44:09.284125Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model_inception.evaluate(test_generator_inception_v3)[1]","metadata":{"execution":{"iopub.status.busy":"2022-08-05T07:44:09.287412Z","iopub.execute_input":"2022-08-05T07:44:09.287788Z","iopub.status.idle":"2022-08-05T07:44:12.105862Z","shell.execute_reply.started":"2022-08-05T07:44:09.287752Z","shell.execute_reply":"2022-08-05T07:44:12.104967Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"f,ax=plt.subplots(2,1,figsize=(10,10)) \n\nax[0].plot(history_inception.history['loss'],label='Training Loss')\nax[0].plot(history_inception.history['val_loss'],label='Validation Loss')\n\nax[1].plot(history_inception.history['accuracy'],label='Training Accuracy')\nax[1].plot(history_inception.history['val_accuracy'],label='Validation Accuracy')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-08-05T07:44:12.107458Z","iopub.execute_input":"2022-08-05T07:44:12.107809Z","iopub.status.idle":"2022-08-05T07:44:12.421890Z","shell.execute_reply.started":"2022-08-05T07:44:12.107773Z","shell.execute_reply":"2022-08-05T07:44:12.421002Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"num_of_test_samples = 100\nbatch_size = 32\nY_pred_inc = model_inception.predict_generator(test_generator_inception_v3, num_of_test_samples // batch_size+1)\ny_pred_inc = np.argmax(Y_pred_inc, axis=1)\nprint('Confusion Matrix')\nconf_matrix_inc = confusion_matrix(test_generator_inception_v3.classes, y_pred_inc)\ncm_inc = np.array2string(conf_matrix_inc)\nprint(conf_matrix_inc)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T07:44:12.424263Z","iopub.execute_input":"2022-08-05T07:44:12.424911Z","iopub.status.idle":"2022-08-05T07:44:14.734677Z","shell.execute_reply.started":"2022-08-05T07:44:12.424874Z","shell.execute_reply":"2022-08-05T07:44:14.733742Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from statistics import mean\ninception_v3_datagen = ImageDataGenerator(\n    rotation_range=20,\n    zoom_range=0.10, \n    brightness_range=[0.6,1.4],\n    channel_shift_range=0.7,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    preprocessing_function=preprocess_input\n)\ninception_v3_datagen_test = ImageDataGenerator(\n    preprocessing_function=preprocess_input\n) \nkf = KFold(n_splits = 10)\nkfold = StratifiedKFold(n_splits=10,shuffle=True,random_state=42)\nresults_inc = []\n\nY = X_train1[['classes']]\n\nfor train_index, val_index in kf.split(np.zeros(400),Y):\n    training_data = X_train1.iloc[train_index]\n    validation_data = X_train1.iloc[val_index]\n    training_set = inception_v3_datagen.flow_from_dataframe(dataframe = training_data, \n                                                      x_col=\"path\", \n                                                      y_col=\"classes\",\n                                                      class_mode=\"categorical\",\n                                                      target_size=(227, 227), \n                                                      batch_size=32)\n    validation_set = inception_v3_datagen.flow_from_dataframe(dataframe = validation_data, \n                                                        x_col = \"path\", \n                                                        y_col = \"classes\",\n                                                        class_mode = \"categorical\",\n                                                        target_size = (227, 227), \n                                                        batch_size = 32)\n    \n    InceptionV3_model = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n    for layer in InceptionV3_model.layers[:-15]:\n        layer.trainable = False\n    x = InceptionV3_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Flatten()(x)\n    x = Dense(units=512, activation='relu')(x)\n    x = Dropout(0.3)(x)\n    x = Dense(units=512, activation='relu')(x)\n    x = Dropout(0.3)(x)\n    output  = Dense(units=5, activation='softmax')(x)\n    model_inception = Model(InceptionV3_model.input, output)\n\n    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n    model_inception.compile(optimizer=optimizer, loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n    history_inception = model_inception.fit(train_generator_inception_v3, steps_per_epoch=4, epochs=25, validation_data=val_generator_inception_v3, validation_steps=2)\n    \n    resu = model_inception.evaluate(test_generator_inception_v3)\n    results_inc.append(resu)\n    print(resu)\nprint(results_inc)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T07:44:14.737138Z","iopub.execute_input":"2022-08-05T07:44:14.737960Z","iopub.status.idle":"2022-08-05T08:22:41.085499Z","shell.execute_reply.started":"2022-08-05T07:44:14.737910Z","shell.execute_reply":"2022-08-05T08:22:41.084407Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# EfficientNet","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.efficientnet import preprocess_input\nEfficientNetB3_datagen = ImageDataGenerator(\n    rotation_range=20,\n    zoom_range=0.10,\n    brightness_range=[0.6,1.4],\n    channel_shift_range=0.7,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    preprocessing_function=preprocess_input\n) \ntrain_generator_EfficientNetB3 = EfficientNetB3_datagen.flow_from_directory(\n        training_dir,  \n        target_size=(300, 300), \n        batch_size=32,\n        class_mode=\"categorical\",\n        shuffle=True,\n)\nval_generator_EfficientNetB3 = EfficientNetB3_datagen.flow_from_directory(\n        validating_dir,  \n        target_size=(300, 300), \n        batch_size=32,\n        class_mode=\"categorical\",\n        shuffle=True,\n)\nEfficientNetB3_datagen_test = ImageDataGenerator(\n    preprocessing_function=preprocess_input\n) \ntest_generator_EfficientNetB3 = EfficientNetB3_datagen_test.flow_from_directory(\n        testing_dir,  \n        target_size=(300, 300), \n        batch_size=32,\n        class_mode=\"categorical\",\n        shuffle=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T08:23:15.307993Z","iopub.execute_input":"2022-08-05T08:23:15.308380Z","iopub.status.idle":"2022-08-05T08:23:15.623276Z","shell.execute_reply.started":"2022-08-05T08:23:15.308350Z","shell.execute_reply":"2022-08-05T08:23:15.622195Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"img_shape=(300, 300, 3)\nmodel_name='EfficientNetB3'\nEfficientNetB3_model=tf.keras.applications.efficientnet.EfficientNetB3(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max') \nfor layer in EfficientNetB3_model.layers[:-15]:\n    layer.trainable = False\nx = EfficientNetB3_model.output\nx = BatchNormalization(axis=-1, epsilon=0.001)(x)\nx = Dense(256,activation='relu')(x)\nx = Dropout(rate=.3)(x)       \noutput=Dense(5, activation='softmax')(x)\nEfficientNetB3_model = Model(inputs=EfficientNetB3_model.input, outputs=output)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T08:23:15.625426Z","iopub.execute_input":"2022-08-05T08:23:15.626395Z","iopub.status.idle":"2022-08-05T08:23:18.539690Z","shell.execute_reply.started":"2022-08-05T08:23:15.626351Z","shell.execute_reply":"2022-08-05T08:23:18.538573Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"EfficientNetB3_model.compile('Adam', loss='categorical_crossentropy', metrics=['accuracy']) \nhistory_eff = EfficientNetB3_model.fit(train_generator_EfficientNetB3, epochs=25, validation_data=val_generator_EfficientNetB3)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T08:23:18.541696Z","iopub.execute_input":"2022-08-05T08:23:18.542044Z","iopub.status.idle":"2022-08-05T08:28:29.153041Z","shell.execute_reply.started":"2022-08-05T08:23:18.542009Z","shell.execute_reply":"2022-08-05T08:28:29.151983Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"EfficientNetB3_model.evaluate(test_generator_EfficientNetB3)[1]","metadata":{"execution":{"iopub.status.busy":"2022-08-05T08:28:29.155113Z","iopub.execute_input":"2022-08-05T08:28:29.155463Z","iopub.status.idle":"2022-08-05T08:28:30.512034Z","shell.execute_reply.started":"2022-08-05T08:28:29.155429Z","shell.execute_reply":"2022-08-05T08:28:30.511128Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"f,ax=plt.subplots(2,1,figsize=(10,10)) \n\nax[0].plot(history_eff.history['loss'],label='Training Loss')\nax[0].plot(history_eff.history['val_loss'],label='Validation Loss')\n\nax[1].plot(history_eff.history['accuracy'],label='Training Accuracy')\nax[1].plot(history_eff.history['val_accuracy'],label='Validation Accuracy')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-08-05T08:28:30.513567Z","iopub.execute_input":"2022-08-05T08:28:30.513914Z","iopub.status.idle":"2022-08-05T08:28:30.813994Z","shell.execute_reply.started":"2022-08-05T08:28:30.513879Z","shell.execute_reply":"2022-08-05T08:28:30.813124Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"num_of_test_samples = 100\nbatch_size = 32\nY_pred_eff = EfficientNetB3_model.predict_generator(test_generator_EfficientNetB3, num_of_test_samples // batch_size+1)\ny_pred_eff = np.argmax(Y_pred_eff, axis=1)\nprint('Confusion Matrix')\nconf_matrix_eff = confusion_matrix(test_generator_EfficientNetB3.classes, y_pred_eff)\ncm_inc = np.array2string(conf_matrix_eff)\nprint(conf_matrix_eff)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T08:28:30.816433Z","iopub.execute_input":"2022-08-05T08:28:30.817266Z","iopub.status.idle":"2022-08-05T08:28:33.477758Z","shell.execute_reply.started":"2022-08-05T08:28:30.817222Z","shell.execute_reply":"2022-08-05T08:28:33.476771Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from statistics import mean\nEfficientNetB3_datagen = ImageDataGenerator(\n    rotation_range=20,\n    zoom_range=0.10,\n    brightness_range=[0.6,1.4],\n    channel_shift_range=0.7,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    preprocessing_function=preprocess_input\n) \n\nkf = KFold(n_splits = 10)\nkfold = StratifiedKFold(n_splits=10,shuffle=True,random_state=42)\nresults_eff = []\n\nY = X_train1[['classes']]\n\nfor train_index, val_index in kf.split(np.zeros(400),Y):\n    training_data = X_train1.iloc[train_index]\n    validation_data = X_train1.iloc[val_index]\n    training_set = EfficientNetB3_datagen.flow_from_dataframe(dataframe = training_data, \n                                                      x_col=\"path\", \n                                                      y_col=\"classes\",\n                                                      class_mode=\"categorical\",\n                                                      target_size=(300, 300), \n                                                      batch_size=32)\n    validation_set = EfficientNetB3_datagen.flow_from_dataframe(dataframe = validation_data, \n                                                        x_col = \"path\", \n                                                        y_col = \"classes\",\n                                                        class_mode = \"categorical\",\n                                                        target_size = (300, 300), \n                                                        batch_size = 32)\n        \n    \n    img_shape=(300, 300, 3)\n    model_name='EfficientNetB3'\n    EfficientNetB3_model=tf.keras.applications.efficientnet.EfficientNetB3(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max') \n    for layer in EfficientNetB3_model.layers[:-15]:\n        layer.trainable = False\n    x = EfficientNetB3_model.output\n    x = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)\n    x = Dense(256,activation='relu')(x)\n    x = Dropout(rate=.4, seed=123)(x)       \n    output=Dense(5, activation='softmax')(x)\n    EfficientNetB3_model = Model(inputs=EfficientNetB3_model.input, outputs=output)\n    \n    EfficientNetB3_model.compile('Adam', loss='categorical_crossentropy', metrics=['accuracy']) \n    history_eff = EfficientNetB3_model.fit(train_generator_EfficientNetB3, epochs=25, validation_data=val_generator_EfficientNetB3)\n    \n    resu = EfficientNetB3_model.evaluate(test_generator_EfficientNetB3)\n    results_eff.append(resu)\n    print(resu)\nprint(results_eff)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T08:28:33.479335Z","iopub.execute_input":"2022-08-05T08:28:33.479685Z","iopub.status.idle":"2022-08-05T09:19:54.863402Z","shell.execute_reply.started":"2022-08-05T08:28:33.479651Z","shell.execute_reply":"2022-08-05T09:19:54.862340Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"# Autoencoder","metadata":{}},{"cell_type":"code","source":"class DataGenerator(Sequence):\n    def __init__(self, df_file, base_dir, output_size, shuffle=False, batch_size=10):\n        self.df = df_file\n        self.base_dir = base_dir\n        self.output_size = output_size\n        self.shuffle = shuffle\n        self.batch_size = batch_size\n        self.on_epoch_end()\n        self.flag = 0\n        self.y_mlp = []\n        self.X_mlp = []\n    def on_epoch_end(self):\n        self.indices = np.arange(len(self.df))\n        if self.shuffle:\n            np.random.shuffle(self.indices)\n    def __len__(self):\n        return int(len(self.df) / self.batch_size)\n    def __getitem__(self, idx):\n        X = np.empty((self.batch_size, *self.output_size, 4))\n        y = x\n        indices = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n        for i, data_index in enumerate(indices):\n            img_path = self.df.iloc[data_index, 0]\n            img = mpimg.imread(img_path)\n            img2 = cv2.resize(img, self.output_size)\n            X[i,] = img2\n            self.X_mlp.append(img2)\n            self.y_mlp.append(self.df.iloc[data_index, 1])\n        return X, X","metadata":{"execution":{"iopub.status.busy":"2022-08-05T13:47:54.757319Z","iopub.execute_input":"2022-08-05T13:47:54.757698Z","iopub.status.idle":"2022-08-05T13:47:54.768878Z","shell.execute_reply.started":"2022-08-05T13:47:54.757665Z","shell.execute_reply":"2022-08-05T13:47:54.767900Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train_generator_autoencoder = DataGenerator( X_train, \"data\", (128, 128), batch_size=8, shuffle=True)\nval_generator_autoencoder = DataGenerator( X_val, \"data\", (128, 128), batch_size=8, shuffle=True)\ntest_generator_autoencoder = DataGenerator( X_test, \"data\", (128, 128), batch_size=8, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T13:47:56.346924Z","iopub.execute_input":"2022-08-05T13:47:56.347288Z","iopub.status.idle":"2022-08-05T13:47:56.353470Z","shell.execute_reply.started":"2022-08-05T13:47:56.347259Z","shell.execute_reply":"2022-08-05T13:47:56.352354Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"len(train_generator_autoencoder.y_mlp)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T13:47:56.870132Z","iopub.execute_input":"2022-08-05T13:47:56.870510Z","iopub.status.idle":"2022-08-05T13:47:56.877883Z","shell.execute_reply.started":"2022-08-05T13:47:56.870462Z","shell.execute_reply":"2022-08-05T13:47:56.876836Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"input_img = keras.Input(shape=(128, 128, 4))\n\nx = layers.Conv2D(256, (5, 5), activation='relu', padding='same')(input_img)\nx = layers.MaxPooling2D((2, 2), padding='same')(x)\nx = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\nx = layers.MaxPooling2D((2, 2), padding='same')(x)\n\nx = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\nencoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n\nencoded2 = layers.Flatten()(encoded)\nencoded2 = layers.Dense(2046)(encoded2)\nx = layers.Dense(16384)(encoded2)\nx = layers.Reshape(target_shape=(16,16,64))(x)\n\nx = layers.Conv2DTranspose(64, (3, 3), strides = 2, activation='relu', padding='same')(x)\nx = layers.Conv2DTranspose(128, (3, 3), strides = 2, activation='relu', padding='same')(x)\nx = layers.Conv2DTranspose(256, (5, 5), strides = 2, activation='relu', padding='same')(x)\ndecoded = layers.Conv2D(4, (3, 3), activation='sigmoid', padding='same')(x)\n\nautoencoder = keras.Model(input_img, decoded)\nautoencoder.compile(optimizer='adam', loss='binary_crossentropy')\nautoencoder.summary()\nplot_model(autoencoder, to_file='OwnCNN_model_plot.png', show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T13:47:58.626190Z","iopub.execute_input":"2022-08-05T13:47:58.626548Z","iopub.status.idle":"2022-08-05T13:47:59.048481Z","shell.execute_reply.started":"2022-08-05T13:47:58.626517Z","shell.execute_reply":"2022-08-05T13:47:59.047305Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"history_autoencoder = autoencoder.fit(train_generator_autoencoder,  \n                                      epochs=15, \n                                      validation_data=val_generator_autoencoder)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T13:48:01.885366Z","iopub.execute_input":"2022-08-05T13:48:01.886431Z","iopub.status.idle":"2022-08-05T13:49:03.582159Z","shell.execute_reply.started":"2022-08-05T13:48:01.886394Z","shell.execute_reply":"2022-08-05T13:49:03.581170Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"encoder = keras.Model(input_img, encoded2)\n\nclass DataGenerator_mlp(Sequence):\n    def __init__(self, df_file, base_dir, output_size, shuffle=False, batch_size=10):\n        self.df = df_file\n        self.base_dir = base_dir\n        self.output_size = output_size\n        self.shuffle = shuffle\n        self.batch_size = batch_size\n        self.on_epoch_end()\n        self.flag = 0\n        self.y_mlp = []\n        self.X_mlp = []\n    def on_epoch_end(self):\n        self.indices = np.arange(len(self.df))\n        if self.shuffle:\n            np.random.shuffle(self.indices)\n    def __len__(self):\n        return int(len(self.df) / self.batch_size)\n    def __getitem__(self, idx):\n        X = np.empty((self.batch_size, *self.output_size, 4))\n        y = x\n        indices = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n        for i, data_index in enumerate(indices):\n            img_path = self.df.iloc[data_index, 0]\n            img = mpimg.imread(img_path)\n            img2 = cv2.resize(img, self.output_size)\n            X[i,] = img2\n            self.X_mlp.append(img2)\n            self.y_mlp.append(self.df.iloc[data_index, 1])\n        return X","metadata":{"execution":{"iopub.status.busy":"2022-08-05T13:49:03.584418Z","iopub.execute_input":"2022-08-05T13:49:03.585000Z","iopub.status.idle":"2022-08-05T13:49:03.600128Z","shell.execute_reply.started":"2022-08-05T13:49:03.584962Z","shell.execute_reply":"2022-08-05T13:49:03.599107Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"train_generator_autoencoder_mlp = DataGenerator_mlp(X_train, \"data\", (128, 128), batch_size=8, shuffle=True)\nval_generator_autoencoder_mlp = DataGenerator_mlp(X_val, \"data\", (128, 128), batch_size=8, shuffle=True)\ntest_generator_autoencoder_mlp = DataGenerator_mlp(X_test, \"data\", (128, 128), batch_size=8, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T13:49:03.601552Z","iopub.execute_input":"2022-08-05T13:49:03.602896Z","iopub.status.idle":"2022-08-05T13:49:03.610681Z","shell.execute_reply.started":"2022-08-05T13:49:03.602861Z","shell.execute_reply":"2022-08-05T13:49:03.609833Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"encoder_train_prediction = encoder.predict(train_generator_autoencoder_mlp)\nencoder_val_prediction = encoder.predict(val_generator_autoencoder_mlp)\nencoder_test_prediction = encoder.predict(test_generator_autoencoder_mlp)\nprint(len(train_generator_autoencoder_mlp.y_mlp))\nprint(len(train_generator_autoencoder_mlp.X_mlp))\nprint(encoder_train_prediction.shape)\nprint(len(val_generator_autoencoder_mlp.y_mlp))\nprint(len(val_generator_autoencoder_mlp.X_mlp))\nprint(encoder_val_prediction.shape)\nprint(len(test_generator_autoencoder_mlp.y_mlp))\nprint(len(test_generator_autoencoder_mlp.X_mlp))\nprint(encoder_test_prediction.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T13:49:03.613788Z","iopub.execute_input":"2022-08-05T13:49:03.614390Z","iopub.status.idle":"2022-08-05T13:49:07.313273Z","shell.execute_reply.started":"2022-08-05T13:49:03.614364Z","shell.execute_reply":"2022-08-05T13:49:07.312301Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"wer = mpimg.imread(X_train['path'][0])\nwer2 = cv2.resize(wer,(512,512))\nplt.imshow(autoencoder.predict(test_generator_autoencoder)[0])\n","metadata":{"execution":{"iopub.status.busy":"2022-08-04T14:25:47.060643Z","iopub.execute_input":"2022-08-04T14:25:47.061788Z","iopub.status.idle":"2022-08-04T14:25:48.142065Z","shell.execute_reply.started":"2022-08-04T14:25:47.061747Z","shell.execute_reply":"2022-08-04T14:25:48.141030Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model_mlp = Sequential()\nmodel_mlp.add(Dense(5000, input_dim=(128)))\nmodel_mlp.add(Activation('relu'))\nmodel_mlp.add(Dropout(0.15))\nmodel_mlp.add(Dense(1000))\nmodel_mlp.add(Activation('relu'))\nmodel_mlp.add(Dropout(0.15))\nmodel_mlp.add(Dense(100))\nmodel_mlp.add(Activation('relu'))\nmodel_mlp.add(Dropout(0.15))\nmodel_mlp.add(Dense(5))\nmodel_mlp.add(Activation('softmax'))\nmodel_mlp.compile(optimizer=Adam(0.001), loss='categorical_crossentropy')\nmodel_mlp.fit(encoder_train_prediction,train_generator_autoencoder_mlp.y_mlp[:320])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = MLPClassifier(hidden_layer_sizes = (2046), \n                    random_state=1, \n                    max_iter=300, \n                    solver = 'sgd',\n                    activation = 'relu').fit(encoder_train_prediction, train_generator_autoencoder_mlp.y_mlp[:320])","metadata":{"execution":{"iopub.status.busy":"2022-08-04T14:25:51.700413Z","iopub.execute_input":"2022-08-04T14:25:51.700776Z","iopub.status.idle":"2022-08-04T14:26:34.476556Z","shell.execute_reply.started":"2022-08-04T14:25:51.700743Z","shell.execute_reply":"2022-08-04T14:26:34.475504Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix\ntest_final_prediction = clf.predict(encoder_test_prediction)\nprint(classification_report(test_generator_autoencoder_mlp.y_mlp[:96], test_final_prediction))","metadata":{"execution":{"iopub.status.busy":"2022-08-04T14:26:34.478466Z","iopub.execute_input":"2022-08-04T14:26:34.479107Z","iopub.status.idle":"2022-08-04T14:26:34.510106Z","shell.execute_reply.started":"2022-08-04T14:26:34.479048Z","shell.execute_reply":"2022-08-04T14:26:34.509076Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"input_img = keras.Input(shape=(128, 128, 4))\n\nx = layers.Conv2D(256, (5, 5), activation='relu', padding='same')(input_img)\nx = layers.MaxPooling2D((2, 2), padding='same')(x)\nx = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\nx = layers.MaxPooling2D((2, 2), padding='same')(x)\n\nx = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\nencoded_second_try = layers.MaxPooling2D((2, 2), padding='same')(x)\n\nx = layers.Conv2DTranspose(64, (3, 3), strides = 2, activation='relu', padding='same')(encoded_second_try)\nx = layers.Conv2DTranspose(128, (3, 3), strides = 2, activation='relu', padding='same')(x)\nx = layers.Conv2DTranspose(256, (5, 5), strides = 2, activation='relu', padding='same')(x)\ndecoded = layers.Conv2D(4, (3, 3), activation='sigmoid', padding='same')(x)\n\nautoencoder2 = keras.Model(input_img, decoded)\nautoencoder2.compile(optimizer='adam', loss='binary_crossentropy')\nautoencoder2.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-05T13:49:07.314782Z","iopub.execute_input":"2022-08-05T13:49:07.315198Z","iopub.status.idle":"2022-08-05T13:49:07.402408Z","shell.execute_reply.started":"2022-08-05T13:49:07.315161Z","shell.execute_reply":"2022-08-05T13:49:07.401209Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"encoder_second_try = keras.Model(input_img, encoded_second_try)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T13:49:10.227010Z","iopub.execute_input":"2022-08-05T13:49:10.227737Z","iopub.status.idle":"2022-08-05T13:49:10.237480Z","shell.execute_reply.started":"2022-08-05T13:49:10.227694Z","shell.execute_reply":"2022-08-05T13:49:10.236292Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"encoder_train_prediction = encoder_second_try.predict(train_generator_autoencoder_mlp)\nencoder_val_prediction = encoder_second_try.predict(val_generator_autoencoder_mlp)\nencoder_test_prediction = encoder_second_try.predict(test_generator_autoencoder_mlp)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T13:49:10.674172Z","iopub.execute_input":"2022-08-05T13:49:10.675582Z","iopub.status.idle":"2022-08-05T13:49:14.939009Z","shell.execute_reply.started":"2022-08-05T13:49:10.675541Z","shell.execute_reply":"2022-08-05T13:49:14.937970Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"print(len(train_generator_autoencoder_mlp.y_mlp))\nprint(len(train_generator_autoencoder_mlp.X_mlp))\nprint(encoder_train_prediction.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T13:49:14.942785Z","iopub.execute_input":"2022-08-05T13:49:14.943138Z","iopub.status.idle":"2022-08-05T13:49:14.949110Z","shell.execute_reply.started":"2022-08-05T13:49:14.943109Z","shell.execute_reply":"2022-08-05T13:49:14.948105Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"inp = Input(shape=(16,16,64))\n\nx = Conv2D(filters=32, kernel_size=(3,3),activation='relu', padding='same')(inp)\nx = Conv2D(filters=32, kernel_size=(3,3),activation='relu', padding='same')(x)\nx = MaxPooling2D(pool_size=2, strides=2,padding='valid')(x)\n\nx = Conv2D(filters=64, kernel_size=(3,3),activation='relu', padding='same')(x)\nx = Conv2D(filters=64, kernel_size=(3,3),activation='relu', padding='same')(x)\nx = MaxPooling2D(pool_size=2, strides=2, padding='valid')(x)\n\nx = Flatten()(x)\nx = Dropout(0.4)(x)\nx = Dense(units=64, activation='relu')(x)\n\nx = Dense(units=1, activation='softmax')(x)\n\nmodel_costume_cnn = Model(inp, x)\nmodel_costume_cnn.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-05T14:19:20.301177Z","iopub.execute_input":"2022-08-05T14:19:20.301806Z","iopub.status.idle":"2022-08-05T14:19:20.364161Z","shell.execute_reply.started":"2022-08-05T14:19:20.301772Z","shell.execute_reply":"2022-08-05T14:19:20.363103Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"y = np.array(train_generator_autoencoder_mlp.y_mlp[:320])\nmodel_costume_cnn.compile('Adam', loss='categorical_crossentropy', metrics=['accuracy']) \nhistory_eff = model_costume_cnn.fit(encoder_train_prediction, y, epochs=25)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}